{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import List\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from pathlib import Path\n",
    "from string import Template\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAR():\n",
    "    def __init__(self):\n",
    "        super(HAR, self).__init__()\n",
    "        self.train_params = {\n",
    "                'num_epochs': 100,\n",
    "                'batch_size': 32,\n",
    "                'weight_decay': 1e-4,\n",
    "                'lambdas': [0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 2, 5, 10],\n",
    "\n",
    "        }\n",
    "        self.alg_hparams = {\n",
    "            'DANN':         {'learning_rate': 1e-2, 'src_cls_loss_wt': 9.74, 'domain_loss_wt': 5.43},\n",
    "            'Deep_Coral':   {'learning_rate': 5e-3, 'src_cls_loss_wt': 8.67, 'coral_wt': 0.44},\n",
    "            'DDC':          {'learning_rate': 5e-3, 'src_cls_loss_wt': 6.24, 'domain_loss_wt': 6.36},\n",
    "            'HoMM':         {'learning_rate': 1e-3, 'src_cls_loss_wt': 2.15, 'domain_loss_wt': 9.13},\n",
    "            'CoDATS':       {'learning_rate': 1e-3, 'src_cls_loss_wt': 6.21, 'domain_loss_wt': 1.72},\n",
    "            'DSAN':         {'learning_rate': 5e-4, 'src_cls_loss_wt': 1.76, 'domain_loss_wt': 1.59},\n",
    "            'AdvSKM':       {'learning_rate': 5e-3, 'src_cls_loss_wt': 3.05, 'domain_loss_wt': 2.876},\n",
    "            'MMDA':         {'learning_rate': 1e-3, 'src_cls_loss_wt': 6.13, 'mmd_wt': 2.37, 'coral_wt': 8.63, 'cond_ent_wt': 7.16},\n",
    "            'CDAN':         {'learning_rate': 1e-2, 'src_cls_loss_wt': 5.19, 'domain_loss_wt': 2.91, 'cond_ent_wt': 1.73},\n",
    "            'DIRT':         {'learning_rate': 5e-4, 'src_cls_loss_wt': 7.00, 'domain_loss_wt': 4.51, 'cond_ent_wt': 0.79, 'vat_loss_wt': 9.31}\n",
    "        }\n",
    "\n",
    "\n",
    "class EEG():\n",
    "    def __init__(self):\n",
    "        super(EEG, self).__init__()\n",
    "        self.train_params = {\n",
    "                'num_epochs': 100,\n",
    "                'batch_size': 128,\n",
    "                'weight_decay': 1e-4,\n",
    "                'lambdas': [0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 2, 5, 10],\n",
    "\n",
    "        }\n",
    "        self.alg_hparams = {\n",
    "            'DANN':         {'learning_rate': 0.0005,   'src_cls_loss_wt': 8.30,    'domain_loss_wt': 0.324, },\n",
    "            'Deep_Coral':   {'learning_rate': 0.0005,   'src_cls_loss_wt': 9.39,    'coral_wt': 0.19, },\n",
    "            'DDC':          {'learning_rate': 0.0005,   'src_cls_loss_wt': 2.951,   'domain_loss_wt': 8.923, },\n",
    "            'HoMM':         {'learning_rate': 0.0005,   'src_cls_loss_wt': 0.197,   'domain_loss_wt': 1.102, },\n",
    "            'CoDATS':       {'learning_rate': 0.01,     'src_cls_loss_wt': 9.239,   'domain_loss_wt': 1.342, },\n",
    "            'DSAN':         {'learning_rate': 0.001,    'src_cls_loss_wt': 6.713,   'domain_loss_wt': 6.708, },\n",
    "            'AdvSKM':       {'learning_rate': 0.0005,   'src_cls_loss_wt': 2.50,    'domain_loss_wt': 2.50, },\n",
    "            'MMDA':         {'learning_rate': 0.0005,   'src_cls_loss_wt': 4.48,    'mmd_wt': 5.951, 'coral_wt': 3.36, 'cond_ent_wt': 6.13, },\n",
    "            'CDAN':         {'learning_rate': 0.001,    'src_cls_loss_wt': 6.803,   'domain_loss_wt': 4.726, 'cond_ent_wt': 1.307, },\n",
    "            'DIRT':         {'learning_rate': 0.005,    'src_cls_loss_wt': 9.183,   'domain_loss_wt': 7.411, 'cond_ent_wt': 2.564, 'vat_loss_wt': 3.583, },\n",
    "        }\n",
    "\n",
    "\n",
    "class WISDM():\n",
    "    def __init__(self):\n",
    "        super(WISDM, self).__init__()\n",
    "        self.train_params = {\n",
    "                'num_epochs': 100,\n",
    "                'batch_size': 32,\n",
    "                'weight_decay': 1e-4,\n",
    "                'lambdas': [0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 2, 5, 10],\n",
    "\n",
    "        }\n",
    "        self.alg_hparams = {\n",
    "            'DANN':         {'learning_rate': 1e-2,     'src_cls_loss_wt': 5.613,   'domain_loss_wt': 1.857},\n",
    "            'Deep_Coral':   {'learning_rate': 0.005,    'src_cls_loss_wt': 8.876,   'coral_wt': 5.56},\n",
    "            'DDC':          {'learning_rate': 1e-3,     'src_cls_loss_wt': 7.01,    'domain_loss_wt': 7.595},\n",
    "            'HoMM':         {'learning_rate': 1e-3,     'src_cls_loss_wt': 0.1913,  'domain_loss_wt': 4.239},\n",
    "            'CoDATS':       {'learning_rate': 1e-3,     'src_cls_loss_wt': 7.187,   'domain_loss_wt': 6.439},\n",
    "            'DSAN':         {'learning_rate': 1e-3,     'src_cls_loss_wt': 0.1,     'domain_loss_wt': 0.1},\n",
    "            'AdvSKM':       {'learning_rate': 1e-3,     'src_cls_loss_wt': 3.05,    'domain_loss_wt': 2.876},\n",
    "            'MMDA':         {'learning_rate': 1e-3,     'src_cls_loss_wt': 0.1,     'mmd_wt': 0.1, 'coral_wt': 0.1, 'cond_ent_wt': 0.4753},\n",
    "            'CDAN':         {'learning_rate': 1e-3,     'src_cls_loss_wt': 9.54,    'domain_loss_wt': 3.283,        'cond_ent_wt': 0.1},\n",
    "            'DIRT':         {'learning_rate': 1e-3,     'src_cls_loss_wt': 0.1,     'domain_loss_wt': 0.1,          'cond_ent_wt': 0.1, 'vat_loss_wt': 0.1}\n",
    "        }\n",
    "\n",
    "\n",
    "class HHAR_SA():\n",
    "    def __init__(self):\n",
    "        super(HHAR_SA, self).__init__()\n",
    "        self.train_params = {\n",
    "                'num_epochs': 100,\n",
    "                'batch_size': 32,\n",
    "                'weight_decay': 1e-4,\n",
    "                'lambdas': [0, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 2, 5, 10],\n",
    "        }\n",
    "        self.alg_hparams = {\n",
    "            'DANN':         {'learning_rate': 0.0005,   'src_cls_loss_wt': 0.9603,  'domain_loss_wt':0.9238},\n",
    "            'Deep_Coral':   {'learning_rate': 0.0005,   'src_cls_loss_wt': 0.05931, 'coral_wt': 8.452},\n",
    "            'DDC':          {'learning_rate': 0.01,     'src_cls_loss_wt':  0.1593, 'domain_loss_wt': 0.2048},\n",
    "            'HoMM':         {'learning_rate': 0.001,     'src_cls_loss_wt': 0.2429,  'domain_loss_wt': 0.9824},\n",
    "            'CoDATS':       {'learning_rate': 0.0005,   'src_cls_loss_wt': 0.5416,  'domain_loss_wt': 0.5582},\n",
    "            'DSAN':         {'learning_rate': 0.005,    'src_cls_loss_wt':0.4133,   'domain_loss_wt': 0.16},\n",
    "            'AdvSKM':       {'learning_rate': 0.001,    'src_cls_loss_wt': 0.4637,  'domain_loss_wt': 0.1511},\n",
    "            'MMDA':         {'learning_rate': 0.001,    'src_cls_loss_wt': 0.9505,  'mmd_wt': 0.5476,           'cond_ent_wt': 0.5167,  'coral_wt': 0.5838, },\n",
    "            'CDAN':         {'learning_rate': 0.001,    'src_cls_loss_wt': 0.6636,  'domain_loss_wt': 0.1954,   'cond_ent_wt':0.0124},\n",
    "            'DIRT':         {'learning_rate': 0.001,    'src_cls_loss_wt': 0.9752,  'domain_loss_wt': 0.3892,   'cond_ent_wt': 0.09228,  'vat_loss_wt': 0.1947}\n",
    "        }\n",
    "        self.name_dict = {'src_cls_loss_wt': 'Classification loss weight', }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {\n",
    "    'DANN':         {'src_cls_loss_wt': 'Classification loss weight', 'domain_loss_wt': 'Domain loss weight'},\n",
    "    'Deep_Coral':   {'src_cls_loss_wt': 'Classification loss weight', 'coral_wt': 'Coral loss weight'},\n",
    "    'DDC':          {'src_cls_loss_wt': 'Classification loss weight', 'domain_loss_wt': 'MMD loss weight'},\n",
    "    'HoMM':         {'src_cls_loss_wt': 'Classification loss weight', 'domain_loss_wt': 'Higher-order-MMD loss weight'},\n",
    "    'CoDATS':       {'src_cls_loss_wt': 'Classification loss weight', 'domain_loss_wt': 'Adversarial loss weight'},\n",
    "    'DSAN':         {'src_cls_loss_wt': 'Classification loss weight', 'domain_loss_wt': 'Local MMD loss weight'},\n",
    "    'AdvSKM':       {'src_cls_loss_wt': 'Classification loss weight', 'domain_loss_wt': 'Adversarial MMD loss weight'},\n",
    "    'MMDA':         {'src_cls_loss_wt': 'Classification loss weight', 'mmd_wt': 'MMD loss weight', 'cond_ent_wt': 'Conditional loss weight',  'coral_wt': 'Coral loss weight', },\n",
    "    'CDAN':         {'src_cls_loss_wt': 'Classification loss weight', 'domain_loss_wt': 'Adversarial loss weight',   'cond_ent_wt': 'Conditional loss weight'},\n",
    "    'DIRT':         {'src_cls_loss_wt': 'Classification loss weight', 'domain_loss_wt': 'Adversarial loss weight',   'cond_ent_wt': 'Conditional loss weight',  'vat_loss_wt': 'Virtual adversarial loss weight'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DANN & Classification loss weight & $9.74$ & $8.3$ & $5.613$ & $0.9603$ \\\\\n",
      " & Domain loss weight & $\\lambda \\times 5.43$ & $\\lambda \\times 0.324$ & $\\lambda \\times 1.857$ & $\\lambda \\times 0.9238$ \\\\\n",
      "\\midrule\n",
      "DeepCoral & Classification loss weight & $8.67$ & $9.39$ & $8.876$ & $0.05931$ \\\\\n",
      " & Coral loss weight & $\\lambda \\times 0.44$ & $\\lambda \\times 0.19$ & $\\lambda \\times 5.56$ & $\\lambda \\times 8.452$ \\\\\n",
      "\\midrule\n",
      "DDC & Classification loss weight & $6.24$ & $2.951$ & $7.01$ & $0.1593$ \\\\\n",
      " & MMD loss weight & $\\lambda \\times 6.36$ & $\\lambda \\times 8.923$ & $\\lambda \\times 7.595$ & $\\lambda \\times 0.2048$ \\\\\n",
      "\\midrule\n",
      "HoMM & Classification loss weight & $2.15$ & $0.197$ & $0.1913$ & $0.2429$ \\\\\n",
      " & Higher-order-MMD loss weight & $\\lambda \\times 9.13$ & $\\lambda \\times 1.102$ & $\\lambda \\times 4.239$ & $\\lambda \\times 0.9824$ \\\\\n",
      "\\midrule\n",
      "CoDATS & Classification loss weight & $6.21$ & $9.239$ & $7.187$ & $0.5416$ \\\\\n",
      " & Adversarial loss weight & $\\lambda \\times 1.72$ & $\\lambda \\times 1.342$ & $\\lambda \\times 6.439$ & $\\lambda \\times 0.5582$ \\\\\n",
      "\\midrule\n",
      "DSAN & Classification loss weight & $1.76$ & $6.713$ & $0.1$ & $0.4133$ \\\\\n",
      " & Local MMD loss weight & $\\lambda \\times 1.59$ & $\\lambda \\times 6.708$ & $\\lambda \\times 0.1$ & $\\lambda \\times 0.16$ \\\\\n",
      "\\midrule\n",
      "AdvSKM & Classification loss weight & $3.05$ & $2.5$ & $3.05$ & $0.4637$ \\\\\n",
      " & Adversarial MMD loss weight & $\\lambda \\times 2.876$ & $\\lambda \\times 2.5$ & $\\lambda \\times 2.876$ & $\\lambda \\times 0.1511$ \\\\\n",
      "\\midrule\n",
      "MMDA & Classification loss weight & $6.13$ & $4.48$ & $0.1$ & $0.9505$ \\\\\n",
      " & MMD loss weight & $\\lambda \\times 2.37$ & $\\lambda \\times 5.951$ & $\\lambda \\times 0.1$ & $\\lambda \\times 0.5476$ \\\\\n",
      " & Conditional loss weight & $\\lambda \\times 7.16$ & $\\lambda \\times 6.13$ & $\\lambda \\times 0.4753$ & $\\lambda \\times 0.5167$ \\\\\n",
      " & Coral loss weight & $\\lambda \\times 8.63$ & $\\lambda \\times 3.36$ & $\\lambda \\times 0.1$ & $\\lambda \\times 0.5838$ \\\\\n",
      "\\midrule\n",
      "CDAN & Classification loss weight & $5.19$ & $6.803$ & $9.54$ & $0.6636$ \\\\\n",
      " & Adversarial loss weight & $\\lambda \\times 2.91$ & $\\lambda \\times 4.726$ & $\\lambda \\times 3.283$ & $\\lambda \\times 0.1954$ \\\\\n",
      " & Conditional loss weight & $\\lambda \\times 1.73$ & $\\lambda \\times 1.307$ & $\\lambda \\times 0.1$ & $\\lambda \\times 0.0124$ \\\\\n",
      "\\midrule\n",
      "DIRT & Classification loss weight & $7.0$ & $9.183$ & $0.1$ & $0.9752$ \\\\\n",
      " & Adversarial loss weight & $\\lambda \\times 4.51$ & $\\lambda \\times 7.411$ & $\\lambda \\times 0.1$ & $\\lambda \\times 0.3892$ \\\\\n",
      " & Conditional loss weight & $\\lambda \\times 0.79$ & $\\lambda \\times 2.564$ & $\\lambda \\times 0.1$ & $\\lambda \\times 0.09228$ \\\\\n",
      " & Virtual adversarial loss weight & $\\lambda \\times 9.31$ & $\\lambda \\times 3.583$ & $\\lambda \\times 0.1$ & $\\lambda \\times 0.1947$ \\\\\n",
      "\\midrule\n"
     ]
    }
   ],
   "source": [
    "def get_param_str(param, lambdas):\n",
    "    p_arr = param * np.array(lambdas)\n",
    "    p_str = '\\{'\n",
    "    for i, p in enumerate(p_arr):\n",
    "        p_str += f'{p:3.4f}'\n",
    "        if i < len(p_arr)-1:\n",
    "            p_str += ','\n",
    "    p_str += '\\}'\n",
    "    return p_str\n",
    "\n",
    "def name_mapping(name):\n",
    "    if name in ['dann', 'cmd', 'mmd']:\n",
    "        return name.upper()\n",
    "    elif name == 'HHAR_SA':\n",
    "        return 'HHAR'\n",
    "    elif name == 'HAR':\n",
    "        return 'UCI-HAR'\n",
    "    elif name == 'EEG':\n",
    "        return 'Sleep-EDF'\n",
    "    elif name == 'MINI_DOMAIN_NET':\n",
    "        return 'MiniDomainNet'\n",
    "    elif name == 'AMAZON_REVIEWS':\n",
    "        return 'Amazon Reviews'\n",
    "    elif name == 'MOONS':\n",
    "        return 'Transformed Moons'\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "hpclasses = [HAR(), EEG(), WISDM(), HHAR_SA()]\n",
    "\n",
    "row_templ_start = '{0} & {1} &'\n",
    "lambdas = hpclasses[0].train_params['lambdas']\n",
    "\n",
    "\n",
    "for alg in hpclasses[0].alg_hparams.keys(): # loop over algorithms\n",
    "    for i, (hp_key, hp_name) in enumerate(name_dict[alg].items()): # loop over hp parameter\n",
    "        if i == 0:\n",
    "            row = row_templ_start.format(alg.replace('_',''), hp_name)\n",
    "        else:\n",
    "            row = row_templ_start.format('', hp_name)\n",
    "        for j, hpclass in enumerate(hpclasses): # loop over datasets\n",
    "            hp_params = hpclass.alg_hparams[alg]\n",
    "            if hp_key == 'src_cls_loss_wt':\n",
    "                p_str = f'${hp_params[hp_key]}$'\n",
    "            else:\n",
    "                p_str = f'$\\lambda \\\\times {hp_params[hp_key]}$'\n",
    "            row += f' {p_str} '\n",
    "            if j < len(hpclasses)-1:\n",
    "                row += '&'\n",
    "            else:\n",
    "                row += '\\\\\\\\'\n",
    "\n",
    "        print(row)\n",
    "    print('\\\\midrule')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d516b6dfc67a13dc7935abd167b5fff5a0712de0723fbeca7c4eccb8b43d9ed2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('bpda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
